#!/usr/bin/env python3
import psycopg2
import sys

LOCAL_DB = {
    'host': 'localhost',
    'port': 5432,
    'database': 'aiinsight',
    'user': 'aiinsight',
    'password': 'aiinsight123'
}

RAILWAY_DB = {
    'host': 'yamanote.proxy.rlwy.net',
    'port': 51273,
    'database': 'railway',
    'user': 'postgres',
    'password': 'yOPQIglOJVBrJtUlCMVhVqLQLhEFLwXg'
}

def migrate_data():
    print("ğŸ”„ ë¡œì»¬ PostgreSQL â†’ Railway PostgreSQL ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
    
    try:
        local_conn = psycopg2.connect(**LOCAL_DB)
        local_cur = local_conn.cursor()
        
        railway_conn = psycopg2.connect(**RAILWAY_DB)
        railway_cur = railway_conn.cursor()
        
        # Railwayì— ìˆëŠ” target_id í™•ì¸
        railway_cur.execute("SELECT id FROM crawl_target")
        valid_target_ids = {row[0] for row in railway_cur.fetchall()}
        print(f"ğŸ“Œ Railway DB ìœ íš¨í•œ íƒ€ê²Ÿ ID: {sorted(valid_target_ids)}")
        
        # 1. news_article ë§ˆì´ê·¸ë ˆì´ì…˜ (ON CONFLICT ì œê±°, ìˆ˜ë™ ì¤‘ë³µ ì²´í¬)
        print("\nğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜...")
        local_cur.execute("SELECT COUNT(*) FROM news_article")
        print(f"   ë¡œì»¬ DB: {local_cur.fetchone()[0]}ê°œ ê¸°ì‚¬")
        
        # Railwayì— ì´ë¯¸ ìˆëŠ” URL í™•ì¸
        railway_cur.execute("SELECT original_url FROM news_article")
        existing_urls = {row[0] for row in railway_cur.fetchall()}
        print(f"   Railway DB ê¸°ì¡´ URL: {len(existing_urls)}ê°œ")
        
        local_cur.execute("""
            SELECT id, target_id, original_url, title, title_ko, content, 
                   summary, author, published_at, relevance_score, 
                   category, importance, is_new, is_summarized, 
                   thumbnail_url, content_hash, crawled_at, updated_at
            FROM news_article
            WHERE target_id = ANY(%s)
            ORDER BY id
        """, (list(valid_target_ids),))
        
        migrated = 0
        skipped = 0
        for article in local_cur.fetchall():
            url = article[2]
            if url in existing_urls:
                skipped += 1
                continue
            
            try:
                railway_cur.execute("""
                    INSERT INTO news_article 
                    (id, target_id, original_url, title, title_ko, content, 
                     summary, author, published_at, relevance_score, 
                     category, importance, is_new, is_summarized, 
                     thumbnail_url, content_hash, crawled_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, article)
                migrated += 1
                railway_conn.commit()
            except Exception as e:
                railway_conn.rollback()
                print(f"   âš ï¸  ê¸°ì‚¬ ID {article[0]} ì‹¤íŒ¨: {e}")
                skipped += 1
        
        print(f"   âœ… {migrated}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜, {skipped}ê°œ ìŠ¤í‚µ")
        
        # 2. crawl_history ë§ˆì´ê·¸ë ˆì´ì…˜ (ìœ íš¨í•œ target_idë§Œ)
        print("\nğŸ“Š í¬ë¡¤ë§ íˆìŠ¤í† ë¦¬ ë§ˆì´ê·¸ë ˆì´ì…˜...")
        local_cur.execute("SELECT COUNT(*) FROM crawl_history")
        print(f"   ë¡œì»¬ DB: {local_cur.fetchone()[0]}ê°œ íˆìŠ¤í† ë¦¬")
        
        local_cur.execute("""
            SELECT id, target_id, status, articles_found, articles_new, 
                   duration_ms, error_message, executed_at
            FROM crawl_history
            WHERE target_id = ANY(%s)
            ORDER BY id
        """, (list(valid_target_ids),))
        
        migrated = 0
        skipped = 0
        for history in local_cur.fetchall():
            try:
                railway_cur.execute("""
                    INSERT INTO crawl_history 
                    (id, target_id, status, articles_found, articles_new, 
                     duration_ms, error_message, executed_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """, history)
                migrated += 1
                railway_conn.commit()
            except psycopg2.errors.UniqueViolation:
                railway_conn.rollback()
                skipped += 1
            except Exception as e:
                railway_conn.rollback()
                print(f"   âš ï¸  íˆìŠ¤í† ë¦¬ ID {history[0]} ì‹¤íŒ¨: {e}")
                skipped += 1
        
        print(f"   âœ… {migrated}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜, {skipped}ê°œ ìŠ¤í‚µ")
        
        # 3. ìµœì¢… í™•ì¸
        print("\nğŸ“Š Railway PostgreSQL ìµœì¢… ìƒíƒœ:")
        railway_cur.execute("SELECT COUNT(*) FROM crawl_target")
        print(f"   í¬ë¡¤ë§ íƒ€ê²Ÿ: {railway_cur.fetchone()[0]}ê°œ")
        
        railway_cur.execute("SELECT COUNT(*) FROM news_article")
        article_count = railway_cur.fetchone()[0]
        print(f"   ë‰´ìŠ¤ ê¸°ì‚¬: {article_count}ê°œ")
        
        railway_cur.execute("SELECT COUNT(*) FROM crawl_history")
        print(f"   í¬ë¡¤ë§ íˆìŠ¤í† ë¦¬: {railway_cur.fetchone()[0]}ê°œ")
        
        if article_count > 0:
            print("\nğŸ“‹ ìµœì‹  ê¸°ì‚¬ ìƒ˜í”Œ:")
            railway_cur.execute("""
                SELECT id, title_ko, title, crawled_at 
                FROM news_article 
                ORDER BY crawled_at DESC 
                LIMIT 5
            """)
            for row in railway_cur.fetchall():
                title = row[1] or row[2]
                print(f"   [{row[0]}] {title[:50]}... ({row[3]})")
        
        local_cur.close()
        local_conn.close()
        railway_cur.close()
        railway_conn.close()
        
        print("\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    migrate_data()
